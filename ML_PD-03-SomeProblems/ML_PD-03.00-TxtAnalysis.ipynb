{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analisi statistica di un testo\n",
    "\n",
    "* Importare il testo contenuto nel file \"I promessi sposi.txt\"\n",
    "* Elaborare il file importato per ottenere una lista di tutte le parole\n",
    "* Stampare nell'ordine alcune informazioni sul testo:\n",
    "    * Numero di frasi, Numero di capitoli\n",
    "    * Numero di parole utilizzate in totale\n",
    "    * Numero di parole univoche utilizzate\n",
    "    * Parola utilizzata di piu'\n",
    "    * Parola piu' lunga\n",
    "    * Parola utilizzata di piu' escludendo congiunzioni e articoli\n",
    "    * Lunghezza media delle parole\n",
    "    * lunghezza media delle frasi\n",
    "    * lunghezza media dei capitoli\n",
    "* Utilizzare le espressioni regolari per rispondere alle seguenti domande:\n",
    "    * Quanti caratteri di newline (\\n) sono stati utilizzati nel testo\n",
    "    * Quanti caratteri di spazio sono stati utilizzati\n",
    "* Quale e' la lettera piu' utilizzata e quella meno utilizzata\n",
    "* Visualizzare un diagramma a barre con le 10 parole piu' utilizzate escluse congiunzioni e articoli\n",
    "* Visualizzare un diagramma che metta evidenza il numero di parole che hanno un determinato numero di lettere\n",
    "* Salvare i risultati della ricerca su un file di tipo csv creato appositamente per il salvataggio dei dati.\n",
    "\n",
    "Cercate online il testo di un altra opera letteraria. [Questo](https://www.liberliber.it/online/opere/libri/istruzioni/) e' un ottimo sito da cui partire per scaricarla legalmente. Ripetere l'analisi.\n",
    "NB: In caso il libro non fosse disponibile in formato .txt, tentare un copia incolla da un file odt. creando la propria versione di testo semplice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importare il testo contenuto nel file \"I promessi sposi.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"manzoni_i_promessi_sposi.txt\"\n",
    "\n",
    "with open(file_name, encoding = \"ANSI\") as my_file:\n",
    "    \n",
    "    entire_file = my_file.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTRODUZIONE\\n  \"L\\'Historia si può veramente deffinire una guerra illustre contro il Tempo, perché togliendoli di mano gl\\'anni suoi prigionieri, anzi già fatti cadaueri, li richiama in vita, li passa in rassegna, e li schiera di nuovo in battaglia. Ma gl\\'illustri Campioni che in tal Arringo fanno messe di Palme e d\\'Allori, rapiscono solo che le sole spoglie più sfarzose e brillanti, imbalsamando co\\' loro inchiostri le Imprese de Prencipi e Potentati, e qualificati Personaggj, e trapontando coll\\'ago finissimo dell\\'ingegno i fili d\\'oro e di seta, che formano un perpetuo ricamo di Attioni gloriose. Però alla mia debolezza non è lecito solleuarsi a tal\\'argomenti, e sublimità pericolose, con aggirarsi tra Labirinti de\\' Politici maneggj, et il rimbombo de\\' bellici Oricalchi: solo che hauendo hauuto notitia di fatti memorabili, se ben capitorno a gente meccaniche, e di piccol affare, mi accingo di lasciarne memoria a Posteri, con far di tutto schietta e genuinamente il Racconto, ouuero sia Rel'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_file[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" – e io, – disse un giorno al suo moralista, – cosa volete che abbia imparato? Io non sono andata a cercare i guai: son loro che sono venuti a cercar me. Quando non voleste dire, – aggiunse, soavemente sorridendo, – che il mio sproposito sia stato quello di volervi bene, e di promettermi a voi.\\n  Renzo, alla prima, rimase impicciato. Dopo un lungo dibattere e cercare insieme, conclusero che i guai vengono bensì spesso, perché ci si è dato cagione; ma che la condotta più cauta e più innocente non basta a tenerli lontani; e che quando vengono, o per colpa o senza colpa, la fiducia in Dio li raddolcisce, e li rende utili per una vita migliore. Questa conclusione, benché trovata da povera gente, c'è parsa così giusta, che abbiam pensato di metterla qui, come il sugo di tutta la storia.\\n  La quale, se non v'è dispiaciuta affatto, vogliatene bene a chi l'ha scritta, e anche un pochino a chi l'ha raccomodata. Ma se in vece fossimo riusciti ad annoiarvi, credete che non s'è fatto apposta.\\n10\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_file[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entire_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elaborare il file importato per ottenere una lista di tutte le parole utilizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_file_original = entire_file\n",
    "entire_file = entire_file.lower()\n",
    "\n",
    "def from_txt_to_list(a_big_string, min_lenght = 0):\n",
    "    pattern = \"[\\W\\d]\" # ruppo che contiene tutti i caratteri non alphanumerici e tutti i numeri\n",
    "    entire_file = a_big_string.lower()\n",
    "\n",
    "    list_of_w = re.sub(pattern,\" \", entire_file).split()\n",
    "\n",
    "#     print(f\"numero di parole = {len(list_of_w)}\")\n",
    "#     print(f\"numero di parole univoche = {len(set(list_of_w))}\")\n",
    "    \n",
    "    # creo il dataframe con le parole \n",
    "\n",
    "    unique_words = Counter(list_of_w)\n",
    "       \n",
    "    chiavi = unique_words.keys()\n",
    "    valori = unique_words.values()\n",
    "    unique_words_df = pd.DataFrame(valori, index = chiavi, columns=[\"occorrenze\"]).sort_index()\n",
    "    \n",
    "    most_common_words = unique_words_df.sort_values(\"occorrenze\", ascending=False)\n",
    "    \n",
    "    # contiamo le lettere di caiscuna parola\n",
    "    unique_words_df[\"len\"] = unique_words_df.index.str.len()\n",
    "    # Filtriamo le parole con meno di n lettere\n",
    "    # Dataframe[condizione] --> Dataframe dove la condizione e' vera\n",
    "    longer_words_df = unique_words_df[unique_words_df[\"len\"] >= min_lenght].sort_values(\"occorrenze\",\n",
    "                                                            ascending = False)\n",
    "    \n",
    "    return list_of_w, longer_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commento questa sezione di codice poiche iserita nella funzione.\n",
    "\n",
    "\n",
    "# print(f\"numero di parole = {len(list_of_w)}\")\n",
    "# print(f\"numero di parole univoche = {len(set(list_of_w))}\")\n",
    "\n",
    "# list_of_w[:10]\n",
    "\n",
    "# chiavi = unique_words.keys()\n",
    "# valori = unique_words.values()\n",
    "\n",
    "# unique_words = Counter(list_of_w)\n",
    "# unique_words_df = pd.DataFrame(valori, index = chiavi, columns=[\"occorrenze\"]).sort_index()\n",
    "\n",
    "# unique_words_df.sort_values(\"occorrenze\", ascending=False)\n",
    "\n",
    "# unique_words_df[\"len\"] = unique_words_df.index.str.len()\n",
    "\n",
    "# unique_words_df[unique_words_df[\"len\"] > 4].sort_values(\"occorrenze\", ascending = False).head(10)\n",
    "\n",
    "# unique_words_df.sort_values(\"len\", ascending=False).head(10)\n",
    "\n",
    "# unique_words_df.loc[\"capitolo\",:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_words, my_df = from_txt_to_list(entire_file_original, min_lenght = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occorrenze</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diligentissimamente</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>straordinariamente</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indeterminatamente</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avvantaggerebbero</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronosticargliele</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>involontariamente</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indipendentemente</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbruciacchiavano</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>particolareggiati</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concigliarglieli</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     occorrenze  len\n",
       "diligentissimamente           1   19\n",
       "straordinariamente            2   18\n",
       "indeterminatamente            1   18\n",
       "avvantaggerebbero             1   17\n",
       "pronosticargliele             1   17\n",
       "involontariamente             2   17\n",
       "indipendentemente             1   17\n",
       "abbruciacchiavano             1   17\n",
       "particolareggiati             1   17\n",
       "concigliarglieli              1   16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.sort_values(\"len\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occorrenze</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>della</th>\n",
       "      <td>938</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quella</th>\n",
       "      <td>766</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anche</th>\n",
       "      <td>762</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aveva</th>\n",
       "      <td>717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disse</th>\n",
       "      <td>612</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renzo</th>\n",
       "      <td>585</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questo</th>\n",
       "      <td>545</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altro</th>\n",
       "      <td>535</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutto</th>\n",
       "      <td>520</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualche</th>\n",
       "      <td>468</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         occorrenze  len\n",
       "della           938    5\n",
       "quella          766    6\n",
       "anche           762    5\n",
       "aveva           717    5\n",
       "disse           612    5\n",
       "renzo           585    5\n",
       "questo          545    6\n",
       "altro           535    5\n",
       "tutto           520    5\n",
       "qualche         468    7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.sort_values(\"occorrenze\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separazione dei Capitolo.\n",
    "\n",
    "Cerco all'interno dle testo grezzo la parola \"CAPITOLO \\*\\*\\*\\n\" come separatore dei gruppi di cui fare l'analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"CAPITOLO [IVXLC]+\"\n",
    "\n",
    "chapters = re.split(pattern, entire_file_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for chapter_number, chapter in enumerate(chapters):\n",
    "    \n",
    "    my_words, my_df = from_txt_to_list(chapter, min_lenght = 0)\n",
    "    \n",
    "    chapter_name = \"Capitolo \" + str(chapter_number)\n",
    "    \n",
    "    results[chapter_name] = [my_words, my_df]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\\n+\"\n",
    "\n",
    "back_slashes = len(re.findall(pattern, entire_file))\n",
    "back_slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219771"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\" +\"\n",
    "\n",
    "spaces = len(re.findall(pattern, entire_file))\n",
    "spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio di un file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.to_csv(\"my_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sentiment Analisys\n",
    "* Cercare online due liste di parole, una che identifichi un sentimento positivo (\"bello\", \"buono\", \"simpatico\" ecc..) una che identifichi dei sentimenti negativi (\"brutto\",\"cattivo\",\"antipatico\", ecc.. ecc..).\n",
    "* Scrivere uno script che prenda in esame un testo e valuti se questo esprime pensieri positivi o negtivi andando a contare le occorrenze nei due gruppi. Testare lo script su ciascun capitolo dei promessi sposi e poi su alcuni tweet reperibili online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"ParolePositiveNegative.txt\"\n",
    "\n",
    "pos_neg_words = pd.read_csv(file_name, names = [\"Positive\", \"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abile</td>\n",
       "      <td>Maldestro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abitudinario</td>\n",
       "      <td>Alternativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accattivante</td>\n",
       "      <td>Insignificante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accogliente</td>\n",
       "      <td>Inospitale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accomodante</td>\n",
       "      <td>Scorbutico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive        Negative\n",
       "0         Abile       Maldestro\n",
       "1  Abitudinario     Alternativo\n",
       "2  Accattivante  Insignificante\n",
       "3   Accogliente      Inospitale\n",
       "4   Accomodante      Scorbutico"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) LAvoriamo sulla lita pulita delle parole del testo da analizzare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cas'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"casa\"[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df[\"depersonalizzata\"] = my_df.index.str[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "come                    com\n",
       "quel                    que\n",
       "della                  dell\n",
       "quella                quell\n",
       "anche                  anch\n",
       "                   ...     \n",
       "informando        informand\n",
       "informaron        informaro\n",
       "informarono      informaron\n",
       "informarsene    informarsen\n",
       "zuffi                  zuff\n",
       "Name: depersonalizzata, Length: 19277, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.depersonalizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_words[\"Pos_depersonalizzata\"] = pos_neg_words.Positive.str[:-1].str.lower()\n",
    "pos_neg_words[\"Neg_depersonalizzata\"] = pos_neg_words.Negative.str[:-1].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = my_df[my_df.depersonalizzata.isin(pos_neg_words[\"Pos_depersonalizzata\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = my_df[my_df.depersonalizzata.isin(pos_neg_words[\"Neg_depersonalizzata\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occorrenze</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.088889</td>\n",
       "      <td>7.818519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.998823</td>\n",
       "      <td>2.169497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.750000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       occorrenze         len\n",
       "count  270.000000  270.000000\n",
       "mean     7.088889    7.818519\n",
       "std     15.998823    2.169497\n",
       "min      1.000000    4.000000\n",
       "25%      1.000000    6.000000\n",
       "50%      2.000000    8.000000\n",
       "75%      5.750000    9.000000\n",
       "max    169.000000   15.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occorrenze</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>221.000000</td>\n",
       "      <td>221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.665158</td>\n",
       "      <td>7.796380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.181465</td>\n",
       "      <td>1.791187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       occorrenze         len\n",
       "count  221.000000  221.000000\n",
       "mean     5.665158    7.796380\n",
       "std     13.181465    1.791187\n",
       "min      1.000000    5.000000\n",
       "25%      1.000000    6.000000\n",
       "50%      2.000000    8.000000\n",
       "75%      5.000000    9.000000\n",
       "max    115.000000   14.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.occorrenze.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1914"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df.occorrenze.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Semplice filtro anti_spam\n",
    "* Scarica online o dalla tua casella di posta una serie dei piu' comuni messaggi spam. Salva questi messaggi in un file di testo accessibile.\n",
    "* Crea con essi una lista di 30 parole o frasi, che piu' comunemente compaiono nei messaggi di spam.\n",
    "* Scrivi uno script che riceva in input dall'utente una mail proveniente dalla sua casella di posta e valuti, assegnando un \"punteggio spam\" generato contando le occorrenze delle parole individuate nel punto precedente, se il messaggio e' o non e' un messaggio di spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Espressioni regolari\n",
    "Per ciascuna delle seguenti, scrivere un testo su cui testare il proprio codice.\n",
    "* 1 Scrivi una espressione regolare che individui in un testo gli indirizzi web del tipo: `http:\\\\www.nome_dominio.estensione` ove _estensione_ e' un gruppo di 2 o piu' lettere.\n",
    "* 2 Scrivere uno script che utilizzi delle espressioni regolari per individuare in un testo alcune date, tenendo presente che potrebbero essere scritte in questi 3 modi:\n",
    "    * 310180\n",
    "    * 31011980\n",
    "    * 31/01/1980\n",
    "* 3 Scrivere uno script che permetta di validare delle password utilizzando delle espressioni regolari. Le password da validare potranno essere di due tipi:\n",
    "    * passfrase formate da almeno 5 parole separate da trattini, trattini bassi, punti o virgole\n",
    "    * password di almeno 8 caratteri tra i quali almeno un numero, una lettera minuscola, una lettera maiuscola e un carattere di punteggiatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.repubblica.it']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_1 = r\"http:\\\\(www\\.\\w+\\.\\w\\w+)\"\n",
    "test1 = \"http:\\\\www.repubblica.it\"\n",
    "re.findall(pattern_1, test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = \"http:\\\\www.repubblica.i\"\n",
    "re.findall(pattern_1, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.repubblica.com']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = \"http:\\\\www.repubblica.com\"\n",
    "re.findall(pattern_1, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = \"http:\\\\www.repubblica\"\n",
    "re.findall(pattern_1, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31011980\n",
      "31/01/1980\n"
     ]
    }
   ],
   "source": [
    "pattern_2 = r\"[0-3]\\d/?[0-1]\\d/?(\\d{2})?\\d{2}\"\n",
    "\n",
    "test_2 = \"\"\"310180\n",
    "31011980\n",
    "31/01/1980\"\"\"\n",
    "\n",
    "for elem in re.finditer(pattern_2, test_2):\n",
    "    print(elem.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310180\n",
      "31011980\n",
      "31/01/1980\n"
     ]
    }
   ],
   "source": [
    "pattern_2 = r\"([0-3]\\d){1}(/)?[0-1]\\d(/)?(\\d{2})?\\d{2}\"\n",
    "\n",
    "test_2 = \"\"\"310180\n",
    "31011980\n",
    "31/01/1980\"\"\"\n",
    "\n",
    "for elem in re.finditer(pattern_2, test_2):\n",
    "    print(elem.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_2 = r\"[0-3]\\d/?[0-1]\\d/?(\\d{2})?\\d{2}\"\n",
    "\n",
    "test_2 = \"\"\"310180\n",
    "31011980\n",
    "31/01/1980\"\"\"\n",
    "\n",
    "for elem in re.finditer(pattern_2, test_2):\n",
    "    print(elem.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analisi dei discorsi dei presidenti della repubblica\n",
    "Su questo sito [del quirinale](https://www.quirinale.it/ricerca/discorsi) sono disponibili tutti i discorsi dell'attuale presidente della repubblica.<br>\n",
    " Cercate nell'archivio i discorsi relativi al messaggio di fine anno su 3 anni consecutivi a vostra scelta, copiate e incollate i testi su altrettanti file di testo e realizzate un'analisi statistica su ciascun testo, mettendo a confronto i risultati anche con diagrammi e tabelle (conteggio delle parole, lunghezza delle frasi, 10 parole piu' lunghe ecc...).<br>\n",
    " Utilizzate opportunamente il codice eventualmente gia' a vostra disposizione utilizzato nel primo degli esercizi di questa pagina.<br>\n",
    " [Qui](https://presidenti.quirinale.it) sono disponibili anche tutti i discorsi di tutti i presidenti della repubblica della storia della repubblica.<br>\n",
    " Ripetere la ricerca con un altro presidente della repubblica, sempre su 3 discorsi di fine anno consecutivi distinti.<br>\n",
    " Mettere a confronto i risultati ottenuti tra i due presidenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}